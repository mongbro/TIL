{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11. pneumonia",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zncX8NdJqYwlvShKPastEY-D9xZEI0Cz",
      "authorship_tag": "ABX9TyOuQtdtT5DKO1yXiOVIFtr1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mongbro/TIL/blob/master/11_pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUZa1Baht-Hh"
      },
      "source": [
        "### keras CNN으로 폐렴 X-Ray 구분하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8oQCg4uw8HS"
      },
      "source": [
        "1. 패키지 수입 및 파라미터 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_0DKgwztc9Y"
      },
      "source": [
        "# 패키지 수입\r\n",
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from time import time\r\n",
        "from sklearn.metrics import confusion_matrix, f1_score\r\n",
        "\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Conv2D, SeparableConv2D\r\n",
        "from keras.layers import Input, Flatten\r\n",
        "from keras.layers import BatchNormalization, MaxPool2D\r\n",
        "from keras.layers import Dense, Dropout\r\n",
        "from keras.preprocessing.image import load_img"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARMCsc_XyYfK"
      },
      "source": [
        "# 파라미터 지정\r\n",
        "MY_EPOCH = 200\r\n",
        "MY_BATCH = 100\r\n",
        "MY_RES = 180\r\n",
        "MY_SHAPE = (MY_RES, MY_RES, 3)\r\n",
        "\r\n",
        "# 모드 설정\r\n",
        "DATA_MODE = 0\r\n",
        "TRAIN_MODE = 1\r\n",
        "MY_PATH = '/content/drive/MyDrive/Colab Notebooks/data/chest'\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHJnajrwFbEm"
      },
      "source": [
        "2. 데이터 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxadiHAKFcZl"
      },
      "source": [
        "# 변수 정의\r\n",
        "  #####################################################################\r\n",
        "  # T_tot : train total 학습용 데이터 이미지 갯수                     #\r\n",
        "  # V_tot : validation total 평가용 데이터 이미지 갯수                #\r\n",
        "  # N_tot : 정상 이미지 갯수                                          #\r\n",
        "  # P_tot : 폐렴 이미지 갯수                                          #\r\n",
        "  # N_path : normal image path 정상 이미지 경로                       #\r\n",
        "  # P_path : pneumonia image path 폐렴 이미지 경로                    #\r\n",
        "  #####################################################################\r\n",
        "\r\n",
        "T_tot = V_tot = N_tot = P_tot = 0\r\n",
        "N_path = P_path = []\r\n",
        "X_train = np.zeros((0))\r\n",
        "Y_train = np.zeros((0))\r\n",
        "X_test = np.zeros((0))\r\n",
        "Y_test = np.zeros((0))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfXC9ZqeGffW"
      },
      "source": [
        "# 학습용 입력 이미지 경로 처리\r\n",
        "def train_path():\r\n",
        "    global T_tot, N_tot, P_tot, N_path, P_path\r\n",
        "    \r\n",
        "    # 정상 이미지 처리\r\n",
        "    dir = os.path.join(MY_PATH, 'train/NORMAL')\r\n",
        "    print(dir)\r\n",
        "    \r\n",
        "    # 정상 이미지 파일 경로\r\n",
        "    N_path = []\r\n",
        "    for f in os.listdir(dir):\r\n",
        "        N_path.append(os.path.join(dir, f))\r\n",
        "    print('학습용 정상 이미지 수 :', len(N_path))\r\n",
        "    N_tot = len(N_path)\r\n",
        "\r\n",
        "    # 폐렴 이미지 처리\r\n",
        "    dir = os.path.join(MY_PATH, 'train/PNEUMONIA')\r\n",
        "    print(dir)\r\n",
        "\r\n",
        "    # 이미지 파일 경로\r\n",
        "    P_path = []\r\n",
        "    for f in os.listdir(dir):\r\n",
        "        P_path.append(os.path.join(dir, f))\r\n",
        "    print('학습용 폐렴 이미지 수 :', len(P_path)) \r\n",
        "    P_tot = len(P_path)\r\n",
        "\r\n",
        "    # 총 학습용 이미지 수\r\n",
        "    T_tot = N_tot + P_tot\r\n",
        "    print('학습용 이미지 수 :', T_tot)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTtrQ2zsMAiN"
      },
      "source": [
        "# 학습용 이미지 데이터 처리 (화상도 통일)\r\n",
        "# 정상 라벨은 0, 폐렴 라벨은 1\r\n",
        "def train_resize():\r\n",
        "    global T_tot, N_tot, P_tot, N_path, P_path\r\n",
        "    global X_train, Y_train\r\n",
        "    print('정상 이미지 처리 시작')\r\n",
        "    begin = time()\r\n",
        "\r\n",
        "    X_train = np.zeros((T_tot, MY_RES, MY_RES, 3))\r\n",
        "    Y_train = np.zeros((T_tot, ))\r\n",
        "    \r\n",
        "    for i, path in enumerate(N_path):\r\n",
        "        #tmp = load_img(path)\r\n",
        "        #print(np.array(tmp).shape)\r\n",
        "        #plt.imshow(tmp)\r\n",
        "        #plt.show()\r\n",
        "        img = load_img(path, \r\n",
        "                       target_size = (MY_RES, MY_RES))\r\n",
        "        #print(np.array(img).shape)\r\n",
        "        #plt.imshow(img)\r\n",
        "        #plt.show()\r\n",
        "        X_train[i] = img\r\n",
        "        Y_train[i] = 0\r\n",
        "        #print(X_train[i].shape)\r\n",
        "        \r\n",
        "    end = time()\r\n",
        "    print(\"정상 이미지 처리 소요 시간 : {:.2f}초\".format(end - begin))\r\n",
        "\r\n",
        "\r\n",
        "########################### 정상 이미지 종료 ###########################\r\n",
        "\r\n",
        "\r\n",
        "    print('폐렴 이미지 처리 시작')\r\n",
        "    begin = time()\r\n",
        "\r\n",
        "    for i, path in enumerate(P_path):\r\n",
        "        img = load_img(path,\r\n",
        "                       target_size = (MY_RES, MY_RES))\r\n",
        "        X_train[i + N_tot] = img\r\n",
        "        Y_train[i + N_tot] = 1\r\n",
        "    \r\n",
        "    # [0, 255] 8비트 컬러 정보를 [0, 1]로 스케일\r\n",
        "    #print(X_train[0])\r\n",
        "    X_train = X_train / 255.0\r\n",
        "\r\n",
        "    end = time()\r\n",
        "    print(\"폐렴 이미지 처리 소요 시간 : {:.2f}초\".format(end - begin))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IdkiSNIiO8j"
      },
      "source": [
        "# 평가용 데이터 경로 처리\r\n",
        "def test_path():\r\n",
        "    global V_tot, N_tot, P_tot, N_path, P_path\r\n",
        "\r\n",
        "    # 정상 이미지 처리\r\n",
        "    dir = os.path.join(MY_PATH, 'test/NORMAL')\r\n",
        "    print(dir)\r\n",
        "    \r\n",
        "    # 정상 이미지 파일 경로\r\n",
        "    N_path = []\r\n",
        "    for f in os.listdir(dir):\r\n",
        "        N_path.append(os.path.join(dir, f))\r\n",
        "    print('평가용 정상 이미지 수 :', len(N_path))\r\n",
        "    N_tot = len(N_path)\r\n",
        "\r\n",
        "    # 폐렴 이미지 처리\r\n",
        "    dir = os.path.join(MY_PATH, 'test/PNEUMONIA')\r\n",
        "    print(dir)\r\n",
        "\r\n",
        "    # 이미지 파일 경로\r\n",
        "    P_path = []\r\n",
        "    for f in os.listdir(dir):\r\n",
        "        P_path.append(os.path.join(dir, f))\r\n",
        "    print('평가용 폐렴 이미지 수 :', len(P_path)) \r\n",
        "    P_tot = len(P_path)\r\n",
        "\r\n",
        "    # 총 평가용 이미지 수\r\n",
        "    V_tot = N_tot + P_tot\r\n",
        "    print('평가용 이미지 수 :', V_tot)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Cj5wYJksIq"
      },
      "source": [
        "# 평가용 이미지 데이터 처리 (화상도 통일)\r\n",
        "# 정상 라벨은 0, 폐렴 라벨은 1\r\n",
        "def test_resize():\r\n",
        "    global V_tot, N_tot, P_tot, N_path, P_path\r\n",
        "    global X_test, Y_test\r\n",
        "    print('정상 이미지 처리 시작')\r\n",
        "    begin = time()\r\n",
        "\r\n",
        "    X_test = np.zeros((V_tot, MY_RES, MY_RES, 3))\r\n",
        "    Y_test = np.zeros((V_tot, ))\r\n",
        "    \r\n",
        "    for i, path in enumerate(N_path):\r\n",
        "        #tmp = load_img(path)\r\n",
        "        #print(np.array(tmp).shape)\r\n",
        "        #plt.imshow(tmp)\r\n",
        "        #plt.show()\r\n",
        "        img = load_img(path, \r\n",
        "                       target_size = (MY_RES, MY_RES))\r\n",
        "        #print(np.array(img).shape)\r\n",
        "        #plt.imshow(img)\r\n",
        "        #plt.show()\r\n",
        "        X_test[i] = img\r\n",
        "        Y_test[i] = 0\r\n",
        "        #print(X_train[i].shape)\r\n",
        "        \r\n",
        "    end = time()\r\n",
        "    print(\"정상 이미지 처리 소요 시간 : {:.2f}초\".format(end - begin))\r\n",
        "\r\n",
        "\r\n",
        "########################### 정상 이미지 종료 ###########################\r\n",
        "\r\n",
        "\r\n",
        "    print('폐렴 이미지 처리 시작')\r\n",
        "    begin = time()\r\n",
        "\r\n",
        "    for i, path in enumerate(P_path):\r\n",
        "        img = load_img(path,\r\n",
        "                       target_size = (MY_RES, MY_RES))\r\n",
        "        X_test[i + N_tot] = img\r\n",
        "        Y_test[i + N_tot] = 1\r\n",
        "    \r\n",
        "    # [0, 255] 8비트 컬러 정보를 [0, 1]로 스케일\r\n",
        "    #print(X_test[0])\r\n",
        "    X_test = X_test / 255.0\r\n",
        "\r\n",
        "    end = time()\r\n",
        "    print(\"폐렴 이미지 처리 소요 시간 : {:.2f}초\".format(end - begin))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVflosG6m6F5"
      },
      "source": [
        "# 사분할 데이터 저장\r\n",
        "def save_data():\r\n",
        "    global X_train, Y_train, X_test, Y_test\r\n",
        "    with open('chest_arrays.npy', 'wb') as f:\r\n",
        "        np.save(f, X_train)\r\n",
        "        np.save(f, Y_train)\r\n",
        "        np.save(f, X_test)\r\n",
        "        np.save(f, Y_test)\r\n",
        "\r\n",
        "    print('데이터 파일 쓰기 완성')\r\n",
        "    print('READ_WAV를 0으로 바꾸고 진행하세요')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdIXhYa6pfbs"
      },
      "source": [
        "# 사분할 데이터 읽기\r\n",
        "def read_data():\r\n",
        "    global X_train, Y_train, X_test, Y_test\r\n",
        "    with open('chest_arrays.npy', 'rb') as f:\r\n",
        "        X_train = np.load(f)\r\n",
        "        Y_train = np.load(f)\r\n",
        "        X_test = np.load(f)\r\n",
        "        Y_test = np.load(f)\r\n",
        "\r\n",
        "    print('데이터 파일 읽기 완성') "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGhNunUBp_cJ",
        "outputId": "28b57f16-defe-4a94-82bb-05f205024809"
      },
      "source": [
        "# 데이터 처리 컨트롤 타워\r\n",
        "if DATA_MODE:\r\n",
        "    train_path()\r\n",
        "    train_resize()\r\n",
        "    test_path()\r\n",
        "    test_resize()\r\n",
        "    save_data()\r\n",
        "else:\r\n",
        "    read_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 파일 읽기 완성\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfn5-GUvS7x",
        "outputId": "0e3fe349-7346-4524-8d85-d47538e5c133"
      },
      "source": [
        "\r\n",
        "# 데이터 모양 확인\r\n",
        "print('학습용 입력 데이터 모양 :', X_train.shape)\r\n",
        "print('학습용 출력 데이터 모양 :', Y_train.shape)\r\n",
        "\r\n",
        "print('평가용 입력 데이터 모양 :', X_test.shape)\r\n",
        "print('평가용 출력 데이터 모양 :', Y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습용 입력 데이터 모양 : (1000, 180, 180, 3)\n",
            "학습용 출력 데이터 모양 : (1000,)\n",
            "평가용 입력 데이터 모양 : (200, 180, 180, 3)\n",
            "평가용 출력 데이터 모양 : (200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKGG_qtA0ihg"
      },
      "source": [
        "3. 인공 신경망 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un069E_t0hxS"
      },
      "source": [
        "# 합성곱 블럭 함수\r\n",
        "def conv_block(filters, inputs):\r\n",
        "    x = SeparableConv2D(filters = filters,\r\n",
        "                        kernel_size = 3,\r\n",
        "                        activation = 'relu',\r\n",
        "                        padding = 'same')(inputs)\r\n",
        "\r\n",
        "    x = SeparableConv2D(filters = filters,\r\n",
        "                        kernel_size = 3,\r\n",
        "                        activation = 'relu',\r\n",
        "                        padding = 'same')(x)\r\n",
        "\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    output = MaxPool2D(pool_size = 2)(x)\r\n",
        "\r\n",
        "    return output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oIycFRt4Wl9"
      },
      "source": [
        "# Dense 블럭 함수\r\n",
        "def dense_block(units, drop, input):\r\n",
        "    x = Dense(units = units,\r\n",
        "              activation = 'relu')(input)\r\n",
        "\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    output = Dropout(drop)(x)\r\n",
        "    \r\n",
        "    return output"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIu5B8sM5FGt",
        "outputId": "69827b47-18e4-43f7-8d8a-177e779c275b"
      },
      "source": [
        "# 전체 CNN 구현\r\n",
        "\r\n",
        "# 입력층\r\n",
        "my_input = Input(shape = (MY_SHAPE))\r\n",
        "\r\n",
        "# 2번 블럭\r\n",
        "x = Conv2D(filters = 16,\r\n",
        "           kernel_size = 3,\r\n",
        "           activation = 'relu',\r\n",
        "           padding = 'same')(my_input)\r\n",
        "\r\n",
        "x = Conv2D(filters = 16,\r\n",
        "           kernel_size = 3,\r\n",
        "           activation = 'relu',\r\n",
        "           padding = 'same')(x)\r\n",
        "\r\n",
        "x = MaxPool2D(pool_size = 2)(x)\r\n",
        "\r\n",
        "# 3번 블럭\r\n",
        "x = conv_block(32, x)\r\n",
        "\r\n",
        "# 4번 블럭\r\n",
        "x = conv_block(64, x)\r\n",
        "\r\n",
        "# 5번 블럭\r\n",
        "x = conv_block(128, x)\r\n",
        "\r\n",
        "# 6번 블럭\r\n",
        "x = conv_block(256, x)\r\n",
        "x = Dropout(0.2)(x)\r\n",
        "\r\n",
        "# 7번 블럭\r\n",
        "x = Flatten()(x)\r\n",
        "\r\n",
        "# 8번 블럭\r\n",
        "x = dense_block(512, 0.7, x)\r\n",
        "x = dense_block(128, 0.5, x)\r\n",
        "x = dense_block(64, 0.3, x)\r\n",
        "\r\n",
        "# 9번 블럭\r\n",
        "my_output = Dense(units = 1,\r\n",
        "          activation = 'sigmoid')(x)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# 모델 만들기\r\n",
        "model = Model(inputs = my_input,\r\n",
        "              outputs = my_output)\r\n",
        "print('CNN 요약')\r\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN 요약\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 180, 180, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 180, 180, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 90, 90, 16)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 90, 90, 32)        688       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 90, 90, 32)        1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 90, 90, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 45, 45, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_10 (Separab (None, 45, 45, 64)        2400      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_11 (Separab (None, 45, 45, 64)        4736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 45, 45, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_12 (Separab (None, 22, 22, 128)       8896      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_13 (Separab (None, 22, 22, 128)       17664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_14 (Separab (None, 11, 11, 256)       34176     \n",
            "_________________________________________________________________\n",
            "separable_conv2d_15 (Separab (None, 11, 11, 256)       68096     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3277312   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,496,801\n",
            "Trainable params: 3,494,433\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtDESzkz_I0r"
      },
      "source": [
        "4. 인공 신경망 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG-1kV5D_FuO",
        "outputId": "63085aaf-9179-4c85-e02e-efdc7348a934"
      },
      "source": [
        "# CNN 학습\r\n",
        "model.compile(optimizer = 'adam',\r\n",
        "              loss = 'binary_crossentropy',\r\n",
        "              metrics = ['acc'])\r\n",
        "\r\n",
        "# 학습 시작\r\n",
        "print('학습 시작')\r\n",
        "begin = time()\r\n",
        "\r\n",
        "model.fit(x = X_train, \r\n",
        "          y = Y_train,\r\n",
        "          epochs = MY_EPOCH,\r\n",
        "          batch_size = MY_BATCH,\r\n",
        "          verbose = 1)\r\n",
        "\r\n",
        "end = time()\r\n",
        "\r\n",
        "print('학습 시간 : {:.2f}초'.format(end - begin))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습 시작\n",
            "Epoch 1/200\n",
            "10/10 [==============================] - 5s 318ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0192 - acc: 0.9908\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0203 - acc: 0.9949\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0164 - acc: 0.9914\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 0.0106 - acc: 0.9965\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0125 - acc: 0.9970\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0175 - acc: 0.9926\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0166 - acc: 0.9961\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0120 - acc: 0.9960\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0294 - acc: 0.9916\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0146 - acc: 0.9966\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0043 - acc: 0.9989\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0050 - acc: 0.9989\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0028 - acc: 0.9990\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0021 - acc: 0.9997\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0020 - acc: 0.9991\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0029 - acc: 0.9989\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0045 - acc: 0.9975\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 3s 310ms/step - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 0.0017 - acc: 0.9998\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0157 - acc: 0.9951\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0037 - acc: 0.9972\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0041 - acc: 0.9979\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0312 - acc: 0.9934\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0044 - acc: 0.9984\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 3s 315ms/step - loss: 0.0076 - acc: 0.9976\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 0.0083 - acc: 0.9978\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0214 - acc: 0.9938\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0233 - acc: 0.9928\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0044 - acc: 0.9973\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 0.0120 - acc: 0.9957\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 0.0073 - acc: 0.9969\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 0.0109 - acc: 0.9947\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0030 - acc: 0.9987\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 3s 328ms/step - loss: 0.0081 - acc: 0.9952\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0064 - acc: 0.9984\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0021 - acc: 0.9993\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 3s 310ms/step - loss: 0.0027 - acc: 0.9997\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0077 - acc: 0.9969\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 0.0064 - acc: 0.9981\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0218 - acc: 0.9913\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0023 - acc: 0.9989\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 0.0154 - acc: 0.9978\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 8.3655e-04 - acc: 1.0000\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0066 - acc: 0.9997\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 9.5979e-04 - acc: 1.0000\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 3s 312ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 3.2331e-04 - acc: 1.0000\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 4.6272e-04 - acc: 1.0000\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 1.6662e-04 - acc: 1.0000\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0026 - acc: 0.9996\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0027 - acc: 0.9989\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 2.5688e-04 - acc: 1.0000\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0038 - acc: 0.9972\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0018 - acc: 0.9993\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0053 - acc: 0.9972\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0017 - acc: 0.9996\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 8.8915e-04 - acc: 0.9995\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0032 - acc: 0.9993\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0091 - acc: 0.9964\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0134 - acc: 0.9958\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0041 - acc: 0.9978\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0016 - acc: 0.9994\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0055 - acc: 0.9979\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0072 - acc: 0.9937\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0071 - acc: 0.9977\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0221 - acc: 0.9937\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0106 - acc: 0.9971\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0298 - acc: 0.9887\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0179 - acc: 0.9913\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0125 - acc: 0.9973\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0025 - acc: 0.9993\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0144 - acc: 0.9980\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0130 - acc: 0.9949\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0077 - acc: 0.9991\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0050 - acc: 0.9992\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0127 - acc: 0.9966\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0027 - acc: 0.9991\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 3s 315ms/step - loss: 0.0064 - acc: 0.9961\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0011 - acc: 0.9996\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 3s 315ms/step - loss: 0.0027 - acc: 0.9993\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 0.0072 - acc: 0.9982\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0027 - acc: 0.9988\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0036 - acc: 0.9986\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0055 - acc: 0.9978\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0130 - acc: 0.9958\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 4.7802e-04 - acc: 1.0000\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 8.7714e-04 - acc: 1.0000\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 0.0034 - acc: 0.9993\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 9.1086e-04 - acc: 1.0000\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 7.9954e-04 - acc: 0.9997\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 3.6808e-04 - acc: 1.0000\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0015 - acc: 0.9993\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 6.2124e-04 - acc: 1.0000\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 8.0944e-04 - acc: 1.0000\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0030 - acc: 0.9978\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 0.0088 - acc: 0.9959\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 1.3692e-04 - acc: 1.0000\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 1.5732e-04 - acc: 1.0000\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0017 - acc: 0.9994\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0100 - acc: 0.9984\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 5.7251e-04 - acc: 1.0000\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0029 - acc: 0.9993\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0026 - acc: 0.9972\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 3s 315ms/step - loss: 0.0037 - acc: 0.9982\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 2.5667e-04 - acc: 1.0000\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0047 - acc: 0.9986\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0014 - acc: 0.9996\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 3.1143e-04 - acc: 1.0000\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 4.7226e-04 - acc: 1.0000\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 2.1843e-04 - acc: 1.0000\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 3.8849e-04 - acc: 1.0000\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 3s 309ms/step - loss: 0.0019 - acc: 0.9996\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 6.4384e-04 - acc: 1.0000\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 3.1442e-04 - acc: 1.0000\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 3s 317ms/step - loss: 3.9555e-04 - acc: 1.0000\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 3.2277e-04 - acc: 1.0000\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 2.3792e-04 - acc: 1.0000\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 4.2852e-04 - acc: 1.0000\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0011 - acc: 0.9991\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 3.6135e-04 - acc: 1.0000\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 2.4067e-04 - acc: 1.0000\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0030 - acc: 0.9972\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 5.3658e-04 - acc: 0.9998\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0049 - acc: 0.9991\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0066 - acc: 0.9982\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0158 - acc: 0.9970\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.0061 - acc: 0.9973\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 2.9274e-04 - acc: 1.0000\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 1.2606e-04 - acc: 1.0000\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 1.8610e-04 - acc: 1.0000\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0017 - acc: 0.9997\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0036 - acc: 0.9992\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0088 - acc: 0.9961\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0031 - acc: 0.9971\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0225 - acc: 0.9928\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0063 - acc: 0.9989\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 3s 316ms/step - loss: 0.0387 - acc: 0.9875\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 0.0185 - acc: 0.9947\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0125 - acc: 0.9949\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0069 - acc: 0.9987\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0045 - acc: 0.9989\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0053 - acc: 0.9978\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0132 - acc: 0.9956\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0084 - acc: 0.9982\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 3s 315ms/step - loss: 0.0069 - acc: 0.9986\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0128 - acc: 0.9922\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0105 - acc: 0.9969\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 0.0014 - acc: 0.9998\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0021 - acc: 0.9993\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0071 - acc: 0.9978\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0011 - acc: 0.9998\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 6.4589e-04 - acc: 1.0000\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 0.0049 - acc: 0.9986\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 0.0078 - acc: 0.9982\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 3s 327ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 3s 312ms/step - loss: 8.0633e-04 - acc: 1.0000\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 9.8269e-04 - acc: 0.9998\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0010 - acc: 0.9998\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 1.7082e-04 - acc: 1.0000\n",
            "Epoch 181/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 0.0018 - acc: 0.9996\n",
            "Epoch 182/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 0.0015 - acc: 0.9989\n",
            "Epoch 183/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 0.0026 - acc: 0.9986\n",
            "Epoch 184/200\n",
            "10/10 [==============================] - 3s 318ms/step - loss: 3.1114e-04 - acc: 1.0000\n",
            "Epoch 185/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 5.2442e-04 - acc: 1.0000\n",
            "Epoch 186/200\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 1.7979e-04 - acc: 1.0000\n",
            "Epoch 187/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 3.5255e-04 - acc: 1.0000\n",
            "Epoch 188/200\n",
            "10/10 [==============================] - 3s 326ms/step - loss: 3.2920e-04 - acc: 1.0000\n",
            "Epoch 189/200\n",
            "10/10 [==============================] - 3s 323ms/step - loss: 1.4066e-04 - acc: 1.0000\n",
            "Epoch 190/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 1.7823e-04 - acc: 1.0000\n",
            "Epoch 191/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 6.1101e-04 - acc: 1.0000\n",
            "Epoch 192/200\n",
            "10/10 [==============================] - 3s 309ms/step - loss: 1.5350e-04 - acc: 1.0000\n",
            "Epoch 193/200\n",
            "10/10 [==============================] - 3s 321ms/step - loss: 3.1958e-04 - acc: 1.0000\n",
            "Epoch 194/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 3.8366e-04 - acc: 1.0000\n",
            "Epoch 195/200\n",
            "10/10 [==============================] - 3s 322ms/step - loss: 2.6417e-04 - acc: 1.0000\n",
            "Epoch 196/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 2.1090e-04 - acc: 1.0000\n",
            "Epoch 197/200\n",
            "10/10 [==============================] - 3s 319ms/step - loss: 3.4345e-04 - acc: 0.9997\n",
            "Epoch 198/200\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.0013 - acc: 0.9995\n",
            "Epoch 199/200\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 1.3689e-04 - acc: 1.0000\n",
            "Epoch 200/200\n",
            "10/10 [==============================] - 3s 320ms/step - loss: 3.4911e-04 - acc: 1.0000\n",
            "학습 시간 : 642.34초\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ5vkvd2B6pV",
        "outputId": "7f0ad777-2af0-4e1a-d757-f7ca5520352e"
      },
      "source": [
        "score = model.evaluate(x = X_test, y = Y_test,\r\n",
        "                       verbose = 1)\r\n",
        "\r\n",
        "print('최종 손실값 : {:.2f}'.format(score[0]))\r\n",
        "print('최종 정확도 : {:.2f}'.format(score[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 29ms/step - loss: 2.1242 - acc: 0.7100\n",
            "최종 손실값 : 2.12\n",
            "최종 정확도 : 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}